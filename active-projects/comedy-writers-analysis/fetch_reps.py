"""
fetch_reps.py  — IMDb Pro rep scraper (uses saved storage state)

Prereqs
-------
1. Run playwright_login.py once to create imdbpro_state.json
2. pip install playwright pandas tqdm
3. playwright install --with-deps
"""

import asyncio, json, re, pandas as pd
from pathlib import Path
from tqdm import tqdm
from playwright.async_api import async_playwright

# ----------------------------------------------------------------------
# Config
# ----------------------------------------------------------------------
STATE_FILE = Path("imdbpro_state.json")   # generated by playwright_login.py
CSV_IN  = "comedy_writers_with_ids.csv"
CSV_OUT = "writers_with_reps.csv"
MAX_CONCURRENT = 3                        # keep IMDb happy

# ----------------------------------------------------------------------
# Helper: fetch agency / manager for one nm_id
# ----------------------------------------------------------------------
async def rep_info(nm_id: str) -> dict:
    async with async_playwright() as pw:
        browser = await pw.chromium.launch()
        ctx = await browser.new_context(storage_state=str(STATE_FILE))
        page = await ctx.new_page()
        try:
            await page.goto(f"https://pro.imdb.com/name/{nm_id}/contact",
                            timeout=60_000)
            await page.wait_for_selector("text=Companies", timeout=15_000)
            html = await page.content()
        finally:
            await browser.close()

    agency  = re.search(r"Agency</span>\s*<span[^>]*>([^<]+)",  html)
    manager = re.search(r"Manager</span>\s*<span[^>]*>([^<]+)", html)
    return {
        "nm_id":   nm_id,
        "agency":  agency.group(1).strip()  if agency  else None,
        "manager": manager.group(1).strip() if manager else None,
    }

# ----------------------------------------------------------------------
# Main batch job
# ----------------------------------------------------------------------
async def main(csv_in=CSV_IN, csv_out=CSV_OUT):
    df = pd.read_csv(csv_in)
    nm_ids = df["imdb_nm_id"].dropna().unique().tolist()

    sem = asyncio.Semaphore(MAX_CONCURRENT)
    results = []

    async def worker(nm):
        async with sem:
            try:
                results.append(await rep_info(nm))
            except Exception as e:
                print("⚠️  Failed", nm, e)
                results.append({"nm_id": nm, "agency": None, "manager": None})

    tasks = [worker(nm) for nm in tqdm(nm_ids, desc="Fetching reps")]
    await asyncio.gather(*tasks)

    reps_df = pd.DataFrame(results)
    merged  = df.merge(reps_df, left_on="imdb_nm_id", right_on="nm_id", how="left")
    merged.drop(columns=["nm_id"], inplace=True)
    merged.to_csv(csv_out, index=False)
    print(f"✅  Saved → {csv_out}")

# ----------------------------------------------------------------------
# Entrypoint
# ----------------------------------------------------------------------
if __name__ == "__main__":
    if not STATE_FILE.exists():
        raise FileNotFoundError(
            f"{STATE_FILE} not found. Run playwright_login.py first.")
    asyncio.run(main())
